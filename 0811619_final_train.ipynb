{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: astroid==2.12.12 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 1)) (2.12.12)\n",
      "Requirement already satisfied: asttokens==2.1.0 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from -r requirements.txt (line 2)) (2.1.0)\n",
      "Requirement already satisfied: backcall==0.2.0 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from -r requirements.txt (line 3)) (0.2.0)\n",
      "Requirement already satisfied: category-encoders==2.5.1.post0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 4)) (2.5.1.post0)\n",
      "Requirement already satisfied: certifi==2022.12.7 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 5)) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer==2.1.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 6)) (2.1.1)\n",
      "Requirement already satisfied: colorama==0.4.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 7)) (0.4.5)\n",
      "Requirement already satisfied: contourpy==1.0.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 8)) (1.0.5)\n",
      "Requirement already satisfied: cycler==0.11.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 9)) (0.11.0)\n",
      "Requirement already satisfied: debugpy==1.6.3 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from -r requirements.txt (line 10)) (1.6.3)\n",
      "Requirement already satisfied: decorator==5.1.1 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from -r requirements.txt (line 11)) (5.1.1)\n",
      "Requirement already satisfied: dill==0.3.5.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 12)) (0.3.5.1)\n",
      "Requirement already satisfied: entrypoints==0.4 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from -r requirements.txt (line 13)) (0.4)\n",
      "Requirement already satisfied: executing==1.2.0 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from -r requirements.txt (line 14)) (1.2.0)\n",
      "Requirement already satisfied: feature-engine==1.5.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 15)) (1.5.2)\n",
      "Requirement already satisfied: fonttools==4.38.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 16)) (4.38.0)\n",
      "Requirement already satisfied: idna==3.4 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 17)) (3.4)\n",
      "Requirement already satisfied: ipykernel==6.17.0 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from -r requirements.txt (line 18)) (6.17.0)\n",
      "Requirement already satisfied: ipython==8.6.0 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from -r requirements.txt (line 19)) (8.6.0)\n",
      "Requirement already satisfied: ipywidgets==8.0.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 20)) (8.0.3)\n",
      "Requirement already satisfied: isort==5.10.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 21)) (5.10.1)\n",
      "Requirement already satisfied: jedi==0.18.1 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from -r requirements.txt (line 22)) (0.18.1)\n",
      "Requirement already satisfied: joblib==1.2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 23)) (1.2.0)\n",
      "Requirement already satisfied: jupyter_client==7.4.4 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from -r requirements.txt (line 24)) (7.4.4)\n",
      "Requirement already satisfied: jupyter_core==4.11.2 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from -r requirements.txt (line 25)) (4.11.2)\n",
      "Requirement already satisfied: jupyterlab-widgets==3.0.4 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 26)) (3.0.4)\n",
      "Requirement already satisfied: kiwisolver==1.4.4 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 27)) (1.4.4)\n",
      "Requirement already satisfied: lazy-object-proxy==1.7.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 28)) (1.7.1)\n",
      "Requirement already satisfied: lightgbm==3.3.4 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 29)) (3.3.4)\n",
      "Requirement already satisfied: matplotlib==3.6.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 30)) (3.6.1)\n",
      "Requirement already satisfied: matplotlib-inline==0.1.6 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from -r requirements.txt (line 31)) (0.1.6)\n",
      "Requirement already satisfied: mccabe==0.7.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 32)) (0.7.0)\n",
      "Requirement already satisfied: nest-asyncio==1.5.6 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from -r requirements.txt (line 33)) (1.5.6)\n",
      "Requirement already satisfied: numpy==1.23.4 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 34)) (1.23.4)\n",
      "Requirement already satisfied: opencv-python==4.6.0.66 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 35)) (4.6.0.66)\n",
      "Requirement already satisfied: packaging==21.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 36)) (21.3)\n",
      "Requirement already satisfied: pandas==1.5.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 37)) (1.5.1)\n",
      "Requirement already satisfied: parso==0.8.3 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from -r requirements.txt (line 38)) (0.8.3)\n",
      "Requirement already satisfied: patsy==0.5.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 39)) (0.5.3)\n",
      "Requirement already satisfied: pickleshare==0.7.5 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from -r requirements.txt (line 40)) (0.7.5)\n",
      "Requirement already satisfied: Pillow==9.2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 41)) (9.2.0)\n",
      "Requirement already satisfied: platformdirs==2.5.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 42)) (2.5.2)\n",
      "Requirement already satisfied: prompt-toolkit==3.0.32 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from -r requirements.txt (line 43)) (3.0.32)\n",
      "Requirement already satisfied: psutil==5.9.4 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from -r requirements.txt (line 44)) (5.9.4)\n",
      "Requirement already satisfied: pure-eval==0.2.2 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from -r requirements.txt (line 45)) (0.2.2)\n",
      "Requirement already satisfied: pycodestyle==2.9.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 46)) (2.9.1)\n",
      "Requirement already satisfied: Pygments==2.13.0 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from -r requirements.txt (line 47)) (2.13.0)\n",
      "Requirement already satisfied: pylint==2.15.4 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 48)) (2.15.4)\n",
      "Requirement already satisfied: pyparsing==3.0.9 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 49)) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil==2.8.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 50)) (2.8.2)\n",
      "Requirement already satisfied: pytz==2022.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 51)) (2022.5)\n",
      "Requirement already satisfied: pywin32==305 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from -r requirements.txt (line 52)) (305)\n",
      "Requirement already satisfied: pyzmq==24.0.1 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from -r requirements.txt (line 53)) (24.0.1)\n",
      "Requirement already satisfied: requests==2.28.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 54)) (2.28.1)\n",
      "Requirement already satisfied: scikit-learn==1.1.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 55)) (1.1.3)\n",
      "Requirement already satisfied: scipy==1.9.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 56)) (1.9.3)\n",
      "Requirement already satisfied: six==1.16.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 57)) (1.16.0)\n",
      "Requirement already satisfied: stack-data==0.6.0 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from -r requirements.txt (line 58)) (0.6.0)\n",
      "Requirement already satisfied: statsmodels==0.13.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 59)) (0.13.5)\n",
      "Requirement already satisfied: threadpoolctl==3.1.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 60)) (3.1.0)\n",
      "Requirement already satisfied: tomli==2.0.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 61)) (2.0.1)\n",
      "Requirement already satisfied: tomlkit==0.11.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 62)) (0.11.5)\n",
      "Requirement already satisfied: torch==1.13.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 63)) (1.13.1)\n",
      "Requirement already satisfied: torchvision==0.14.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 64)) (0.14.1)\n",
      "Requirement already satisfied: tornado==6.2 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from -r requirements.txt (line 65)) (6.2)\n",
      "Requirement already satisfied: tqdm==4.64.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 66)) (4.64.1)\n",
      "Requirement already satisfied: traitlets==5.5.0 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from -r requirements.txt (line 67)) (5.5.0)\n",
      "Requirement already satisfied: typing_extensions==4.4.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 68)) (4.4.0)\n",
      "Requirement already satisfied: urllib3==1.26.13 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 69)) (1.26.13)\n",
      "Requirement already satisfied: wcwidth==0.2.5 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from -r requirements.txt (line 70)) (0.2.5)\n",
      "Requirement already satisfied: widgetsnbextension==4.0.4 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 71)) (4.0.4)\n",
      "Requirement already satisfied: wrapt==1.14.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 72)) (1.14.1)\n",
      "Requirement already satisfied: wheel in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from lightgbm==3.3.4->-r requirements.txt (line 29)) (0.38.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import gc; gc.enable()\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import category_encoders as ce\n",
    "from sklearn.linear_model import HuberRegressor, RANSACRegressor,QuantileRegressor, TheilSenRegressor\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Ridge, RidgeCV, SGDRegressor\n",
    "import warnings; warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pd.options.display.max_columns = 50\n",
    "\n",
    "TRAIN_PATH = \"./train.csv\"\n",
    "TEST_PATH = \"./test.csv\"\n",
    "#save data after processing\n",
    "AFTER_PROCESS_TRAIN_PATH = \"./after_train.csv\"\n",
    "AFTER_PROCESS_TEST_PATH = \"./after_test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(TRAIN_PATH)\n",
    "test_df = pd.read_csv(TEST_PATH)\n",
    "#train_df.head()\n",
    "#test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(train_df.isna().sum())\n",
    "#print(test_df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nmeasurement data range\\n3 21.499 13.968\\n4 16.484 8.008\\n5 21.425 12.073\\n6 21.543 12.715\\n7 15.419 7.968\\n8 23.807 15.217\\n9 15.412 7.537\\n10 22.479 9.323\\n11 25.64 12.461\\n12 17.663 5.167\\n13 22.713 10.89\\n14 22.303 9.14\\n15 21.626 9.104\\n16 24.094 9.701\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(train_df['measurement_0'].value_counts())#0-29\n",
    "#print(\"================\")\n",
    "#print(train_df['measurement_1'].value_counts())#0-29\n",
    "#print(\"================\")\n",
    "#print(train_df['measurement_2'].value_counts())#0-24\n",
    "#print(\"================\")\n",
    "#attribute_0~3\n",
    "#A:7,8,9,5\n",
    "#B:5,5,8,8\n",
    "#C:7,8,5,8\n",
    "#D:7,5,6,6\n",
    "#E:7,6,6,9\n",
    "#F:5,6,6,4\n",
    "#G:5,6,9,7\n",
    "#H:7,7,7,9\n",
    "#I:7,5,9,5\n",
    "#print(\"================\")\n",
    "#for measurement 3~16 他們的上下界很接近，最大約20，表示這些資料很集中\n",
    "#for i in range(3,17):\n",
    "#    print(i, train_df[f'measurement_{i}'].max(), train_df[f'measurement_{i}'].min())\n",
    "\"\"\" \n",
    "measurement data range\n",
    "3 21.499 13.968\n",
    "4 16.484 8.008\n",
    "5 21.425 12.073\n",
    "6 21.543 12.715\n",
    "7 15.419 7.968\n",
    "8 23.807 15.217\n",
    "9 15.412 7.537\n",
    "10 22.479 9.323\n",
    "11 25.64 12.461\n",
    "12 17.663 5.167\n",
    "13 22.713 10.89\n",
    "14 22.303 9.14\n",
    "15 21.626 9.104\n",
    "16 24.094 9.701\n",
    "\"\"\"\n",
    "# 1: 3, 5, 6, 8, 11\n",
    "# 2: 4, 7, 9, 12\n",
    "# 3: 10, 13, 14, 15, 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds_dict = {f'Fold 1': [['A', 'B', 'C'], ['D', 'E']],\n",
    "               'Fold 2': [['A', 'B', 'D'], ['C', 'E']],\n",
    "               'Fold 3': [['A', 'B', 'E'], ['C', 'D']],\n",
    "               'Fold 4': [['A', 'C', 'D'], ['B', 'E']],\n",
    "               'Fold 5': [['A', 'C', 'E'], ['B', 'D']],\n",
    "               'Fold 6': [['A', 'D', 'E'], ['B', 'C']],\n",
    "               'Fold 7': [['B', 'C', 'D'], ['A', 'E']],\n",
    "               'Fold 8': [['B', 'C', 'E'], ['A', 'D']],\n",
    "               'Fold 9': [['B', 'D', 'E'], ['A', 'C']],\n",
    "               'Fold 10': [['C', 'D', 'E'], ['A', 'B']] \n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['loading', 'm1', 'm2', 'measurement_17', 'measurement_0', 'measurement_1', 'measurement_2', \n",
    "            'measurement_median', 'measurement_max', 'measurement_min', 'measurement_skew']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n0.25/0.2/\\nA:8,5,6/,7/,4\\nB:7,4,5/,9,3/\\nC:8,5,7,9//-,6 - mean it large between 0.2\\nD:6,5,8,7//,3\\nE:6,8,5,4//,9\\nF:6,4,7,5//-,16\\nG:6,4,8,9//,5\\nH:5,9,4,8,7//\\nI:8,3,7/,9/,4\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(\"============== test measurement_17 ==============\")\n",
    "\n",
    "#data = pd.concat([train_df, test_df])\n",
    "\n",
    "#dro_col = [col for col in test_df.columns if 'measurement' not in col] + ['measurement_0', 'measurement_1', 'measurement_2']\n",
    "#for x in data.product_code.unique() : #x is the value in A,B,C,D,E,F,G,H,I\n",
    "#    corr = np.absolute(data[data.product_code == x].drop(dro_col, axis=1).corr()['measurement_17']).sort_values(ascending=False)\n",
    "#    print(f'{x}:', corr)\n",
    "\n",
    "\"\"\"\n",
    "0.25/0.2/\n",
    "A:8,5,6/,7/,4\n",
    "B:7,4,5/,9,3/\n",
    "C:8,5,7,9//-,6 - mean it large between 0.2\n",
    "D:6,5,8,7//,3\n",
    "E:6,8,5,4//,9\n",
    "F:6,4,7,5//-,16\n",
    "G:6,4,8,9//,5\n",
    "H:5,9,4,8,7//\n",
    "I:8,3,7/,9/,4\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def related_processing(train, test):\n",
    "    data = pd.concat([train, test])\n",
    "\n",
    "    related_dict ={}\n",
    "    related_dict['measurement_17'] = {\n",
    "        'A': ['measurement_8','measurement_5','measurement_6','measurement_7'],\n",
    "        'B': ['measurement_7','measurement_4','measurement_5','measurement_9'],\n",
    "        'C': ['measurement_8','measurement_5','measurement_7','measurement_9'],\n",
    "        'D': ['measurement_6','measurement_5','measurement_8','measurement_7'],\n",
    "        'E': ['measurement_6','measurement_8','measurement_5','measurement_4'],\n",
    "        'F': ['measurement_6','measurement_4','measurement_7','measurement_5'],\n",
    "        'G': ['measurement_6','measurement_4','measurement_8','measurement_9'], \n",
    "        'H': ['measurement_5','measurement_9','measurement_4','measurement_8'],\n",
    "        'I': ['measurement_8','measurement_3','measurement_7','measurement_9']\n",
    "    }\n",
    "    \n",
    "    # collect the name of the next 10 best measurement columns sorted by correlation (except 17 already done above):\n",
    "    dro_col = [col for col in test.columns if 'measurement' not in col] + ['measurement_0', 'measurement_1', 'measurement_2']\n",
    "    correlation_sum = []\n",
    "    selected_columns = []\n",
    "    \n",
    "    # 看 measurement 彼此間的關係相不相近\n",
    "    for x in range(3,17):\n",
    "        #absolute 算絕對值, drop the column in col\n",
    "        corr = np.absolute(data.drop(dro_col, axis=1).corr()[f'measurement_{x}']).sort_values(ascending=False)\n",
    "        correlation_sum.append(np.round(np.sum(corr[1:4]),3)) # 取到小數點後第三位\n",
    "        selected_columns.append(f'measurement_{x}')\n",
    "    \n",
    "    correlation_rank = pd.DataFrame()\n",
    "    correlation_rank['Selected columns'] = selected_columns\n",
    "    correlation_rank['correlation sum'] = correlation_sum\n",
    "    correlation_rank = correlation_rank.sort_values(by = 'correlation sum', ascending = False).reset_index(drop = True)\n",
    "    print(f'Columns selected by the correlation sum : ')\n",
    "    display(correlation_rank.head(14))\n",
    "\n",
    "    for i in range(12):\n",
    "        # from c 取 top 12\n",
    "        measurement_col = correlation_rank.iloc[i, 0]\n",
    "        fill_dict = {}\n",
    "\n",
    "        for x in data.product_code.unique() : # x's value : A,B,C,D,E,F,G,H,I\n",
    "            # 在 product X 中以 measurement_col 為基準去取 corr\n",
    "            corr = np.absolute(data[data.product_code == x].drop(dro_col, axis=1).corr()[measurement_col]).sort_values(ascending=False)\n",
    "            fill_dict[x] = corr[1:5].index.tolist()\n",
    "\n",
    "        related_dict[measurement_col] = fill_dict\n",
    "    #related dict -> 對product X的 measurement_? 取四個相近的measurement 參數\n",
    "    return related_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_processing(df_train, df_test, related_dict):\n",
    "    data = pd.concat([df_train, df_test])\n",
    "    \n",
    "    feature = [col for col in df_test.columns if col.startswith('measurement') or col=='loading']\n",
    "    \n",
    "    #select the column if it has any row is NAN\n",
    "    null_cols = [col for col in df_train.columns if df_train[col].isnull().sum()!=0]\n",
    "    \n",
    "    # according to the full_fill_dict(key, value) to decide the NAN in key through value bt linear model(if value has any NAN)\n",
    "    # others will decide by KNN model \n",
    "    for code in data.product_code.unique(): # A~I\n",
    "        total_na_filled_by_linear_model = 0\n",
    "        print(f'\\n-------- Product code {code} ----------\\n')\n",
    "        \n",
    "        for measurement_col in list(related_dict.keys()):\n",
    "            tmp = data[data.product_code == code]\n",
    "            related_column = related_dict[measurement_col][code]\n",
    "            #train the data which column is measurement & other column is not NAN by HuberRegressor\n",
    "            tmp_train = tmp[related_column+[measurement_col]].dropna(how='any')\n",
    "            tmp_test = tmp[(tmp[related_column].isnull().sum(axis=1)==0)&(tmp[measurement_col].isnull())]\n",
    "            \n",
    "            model = HuberRegressor(epsilon=1.9, max_iter=300)#default //0.59116\n",
    "            #model = RANSACRegressor()//0.59095\n",
    "            #model = TheilSenRegressor()//0.59104\n",
    "            #model = LinearRegression()//0.59112\n",
    "            #model = Ridge(alpha=4.0)#//0.59122\n",
    "            #model = RidgeCV()//0.59116\n",
    "            #model = SGDRegressor()//0.59116\n",
    "            model.fit(tmp_train[related_column], tmp_train[measurement_col])\n",
    "            data.loc[(data.product_code==code)&(data[related_column].isnull().sum(axis=1)==0)&(data[measurement_col].isnull()),measurement_col] = model.predict(tmp_test[related_column])\n",
    "            total_na_filled_by_linear_model += len(tmp_test)\n",
    "        \n",
    "        # others NA columns:\n",
    "        NA = data.loc[data[\"product_code\"] == code,null_cols ].isnull().sum().sum()\n",
    "        model1 = KNNImputer(n_neighbors=3, weights='uniform')\n",
    "        data.loc[data.product_code==code, feature] = model1.fit_transform(data.loc[data.product_code==code, feature])\n",
    "        #KNN only 0.58948\n",
    "        #model_sim = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "        #data.loc[data.product_code==code, feature] = model_sim.fit_transform(data.loc[data.product_code==code, feature])\n",
    "\n",
    "        #SimpleImputer mean//0.59031\n",
    "        #SimpleImputer median//0.59048\n",
    "        #SimpleImputer most_frequent//0.59103 //only 0.59056\n",
    "        print(f'{total_na_filled_by_linear_model} filled by linear model ') \n",
    "        print(f'{NA} filled by KNN ')\n",
    "\n",
    "\n",
    "    data['measurement_median'] = data[[f'measurement_{i}' for i in range(3, 17)]].median(axis=1)\n",
    "    data['measurement_max'] = data[[f'measurement_{i}' for i in range(3, 17)]].max(axis=1)\n",
    "    data['measurement_min'] = data[[f'measurement_{i}' for i in range(3, 17)]].min(axis=1)\n",
    "    data['measurement_skew'] = data[[f'measurement_{i}' for i in range(3, 17)]].skew(axis=1)\n",
    "    \n",
    "    df_train = data.iloc[:df_train.shape[0],:]\n",
    "    df_test = data.iloc[df_train.shape[0]:,:]\n",
    "\n",
    "    # material1 with its size\n",
    "    encoder = ce.CatBoostEncoder(cols = ['attribute_0', 'attribute_2'])\n",
    "    encoder.fit(df_train, df_train['failure'])\n",
    "    df_train = encoder.transform(df_train)\n",
    "    df_test = encoder.transform(df_test)\n",
    "    \n",
    "    # material2 with its size\n",
    "    encoder = ce.CatBoostEncoder(cols = ['attribute_1', 'attribute_3'])\n",
    "    encoder.fit(df_train, df_train['failure'])\n",
    "    df_train = encoder.transform(df_train)\n",
    "    df_test = encoder.transform(df_test)\n",
    "\n",
    "    #Target 59121 the same as Catboost\n",
    "\n",
    "    df_train['m1'] = df_train['attribute_0'] * df_train['attribute_2']\n",
    "    df_train['m2'] = df_train['attribute_1'] * df_train['attribute_3']\n",
    "    df_test['m1'] = df_test['attribute_0'] * df_test['attribute_2']\n",
    "    df_test['m2'] = df_test['attribute_1'] * df_test['attribute_3']\n",
    "\n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns selected by the correlation sum : \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Selected columns</th>\n",
       "      <th>correlation sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>measurement_8</td>\n",
       "      <td>0.454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>measurement_5</td>\n",
       "      <td>0.386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>measurement_6</td>\n",
       "      <td>0.365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>measurement_11</td>\n",
       "      <td>0.342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>measurement_7</td>\n",
       "      <td>0.336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>measurement_4</td>\n",
       "      <td>0.331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>measurement_16</td>\n",
       "      <td>0.252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>measurement_10</td>\n",
       "      <td>0.244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>measurement_14</td>\n",
       "      <td>0.225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>measurement_9</td>\n",
       "      <td>0.201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>measurement_15</td>\n",
       "      <td>0.197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>measurement_13</td>\n",
       "      <td>0.166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>measurement_12</td>\n",
       "      <td>0.142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>measurement_3</td>\n",
       "      <td>0.090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Selected columns  correlation sum\n",
       "0     measurement_8            0.454\n",
       "1     measurement_5            0.386\n",
       "2     measurement_6            0.365\n",
       "3    measurement_11            0.342\n",
       "4     measurement_7            0.336\n",
       "5     measurement_4            0.331\n",
       "6    measurement_16            0.252\n",
       "7    measurement_10            0.244\n",
       "8    measurement_14            0.225\n",
       "9     measurement_9            0.201\n",
       "10   measurement_15            0.197\n",
       "11   measurement_13            0.166\n",
       "12   measurement_12            0.142\n",
       "13    measurement_3            0.090"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------- Product code A ----------\n",
      "\n",
      "2728 filled by linear model \n",
      "1121 filled by KNN \n",
      "\n",
      "-------- Product code B ----------\n",
      "\n",
      "2898 filled by linear model \n",
      "1077 filled by KNN \n",
      "\n",
      "-------- Product code C ----------\n",
      "\n",
      "3134 filled by linear model \n",
      "1210 filled by KNN \n",
      "\n",
      "-------- Product code D ----------\n",
      "\n",
      "2938 filled by linear model \n",
      "1035 filled by KNN \n",
      "\n",
      "-------- Product code E ----------\n",
      "\n",
      "3080 filled by linear model \n",
      "1052 filled by KNN \n",
      "\n",
      "-------- Product code F ----------\n",
      "\n",
      "2999 filled by linear model \n",
      "1074 filled by KNN \n",
      "\n",
      "-------- Product code G ----------\n",
      "\n",
      "2840 filled by linear model \n",
      "1084 filled by KNN \n",
      "\n",
      "-------- Product code H ----------\n",
      "\n",
      "2834 filled by linear model \n",
      "1049 filled by KNN \n",
      "\n",
      "-------- Product code I ----------\n",
      "\n",
      "2858 filled by linear model \n",
      "971 filled by KNN \n"
     ]
    }
   ],
   "source": [
    "# data adjust\n",
    "related_dict = related_processing(train_df, test_df)\n",
    "df_train, df_test = data_processing(train_df, test_df, related_dict)\n",
    "# save data after adjust\n",
    "df_train.to_csv(AFTER_PROCESS_TRAIN_PATH, index=False)\n",
    "df_test.to_csv(AFTER_PROCESS_TEST_PATH, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 AUC score : 0.5861177210355131\n",
      "Fold 2 AUC score : 0.5811713672909862\n",
      "Fold 3 AUC score : 0.5855552332671248\n",
      "Fold 4 AUC score : 0.5876361402932417\n",
      "Fold 5 AUC score : 0.5965361011815244\n",
      "Fold 6 AUC score : 0.5889862795669131\n",
      "Fold 7 AUC score : 0.5855714221701793\n",
      "Fold 8 AUC score : 0.5944137441193753\n",
      "Fold 9 AUC score : 0.5821074931219702\n",
      "Fold 10 AUC score : 0.590175372731446\n",
      "\n",
      "average AUC score: 0.5878270874778274\n"
     ]
    }
   ],
   "source": [
    "test_predictions = np.zeros((df_test.shape[0], 1))\n",
    "\n",
    "auc_score = []\n",
    "\n",
    "for fold in folds_dict.keys():\n",
    "    \n",
    "    x_train = df_train[df_train['product_code'].isin(folds_dict[fold][0])][features].values\n",
    "    y_train = df_train[df_train['product_code'].isin(folds_dict[fold][0])]['failure'].values\n",
    "    x_valid = df_train[df_train['product_code'].isin(folds_dict[fold][1])][features].values \n",
    "    y_valid = df_train[df_train['product_code'].isin(folds_dict[fold][1])]['failure'].values\n",
    "    \n",
    "    model = LogisticRegression(max_iter=500, C=0.15, dual=False, penalty=\"l2\", solver='lbfgs')\n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    # save model\n",
    "    torch.save(model, f'model{fold}.pt')\n",
    "\n",
    "    # check AUC score\n",
    "    predictions = model.predict_proba(x_valid)[:, 1].reshape(-1, 1)\n",
    "    score = roc_auc_score(y_valid, predictions)\n",
    "    auc_score.append(score)\n",
    "    print(f'{fold} AUC score : {score}')\n",
    "\n",
    "#每個fold計算依次最後取平均\n",
    "print(f'\\naverage AUC score: {np.mean(np.array(auc_score))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission_model_test1.csv C = 0.25\n",
    "#submission_model_test2.csv C = 0.4\n",
    "#submission_model_test3.csv C = 0.15 best private score\n",
    "#submission_model_test3_1.csv C = 0.15 iter=800 not influence\n",
    "#submission_model_test4.csv C = 0.2\n",
    "#submission_model_pretest1.csv didn't use 3,5missing\n",
    "#submission_model_pretest2.csv not 3,5missing & median\n",
    "#submission_model_pretest3.csv not 3,5missing & add encode attribute_1 & add measurement_max\n",
    "#submission_model_pretest4.csv not 3,5missing & add encode attribute_1 & with all the measurement->is bad result\n",
    "#submission_model_pretest5.csv not 3,5missing & add encode attribute_1 & without median\n",
    "#submission_model_pretest6.csv not 3,5missing & use m1,m2 not (attribute0,1 & area)//0.59018\n",
    "#submission_model_lbfgs.csv use lbfgs logisticregression model //0.5904\n",
    "#submission_model_liblinear.csv use liblinear logisticregression model //0.5904\n",
    "#submission_model_sag.csv use sag logisticregression model //0.59033\n",
    "#submission_model_saga.csv use saga logisticregression model //0.59019\n",
    "#submission_model_foldv1.csv use fold_dict & fold_dict2 ,they occupy 70% and 30%\n",
    "#submission_model_foldv2.csv use fold_dict2\n",
    "#submission_model_foldv3.csv use fold_dict & fold_dict2 ,they occupy 50% and 50%\n",
    "#submission_model_foldv4.csv use fold_dict & fold_dict2 ,they occupy 80% and 20%\n",
    "#submission_model_17v1.csv measurement_17 set 3 related //0.5907\n",
    "#submission_model_17v2.csv measurement_17 set 4 related //0.59121\n",
    "#submission_model_17v3.csv measurement_17 set 5 related //0.59086\n",
    "#submission_model_17v4.csv measurement_17 set related > 0.25 //0.59078\n",
    "#submission_model_17v5.csv measurement_17 set related > 0.2 //0.59097\n",
    "#submission_model_17v6.csv measurement_17 set add large from 0.2//0.59121\n",
    "#submission_model_knnv1.csv knn neighbor = 5 //59109\n",
    "#submission_model_knnv2.csv knn neighbor = 4 //59117\n",
    "#submission_model_knnv3.csv knn neighbor = 2 //59089\n",
    "#submission_model_epv1.csv ep = 1.6 //59114\n",
    "#submission_model_epv2.csv ep = 1.7 //59119\n",
    "#submission_model_epv3.csv ep = 1.8 //59121\n",
    "#submission_model_.csv ep = 1.9 //59121"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "df95319d8ce4e1d89f5365ae10992bc1f65da593082b1d264e8f529830ec2f02"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
